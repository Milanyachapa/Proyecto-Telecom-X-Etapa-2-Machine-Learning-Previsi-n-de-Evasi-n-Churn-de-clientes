# Proyecto: Telecom X - Etapa 2 - Machine Learning para Churn de Clientes  
**Repositorio:** `ml_churn`

---

## √çndice üìã  
1. Descripci√≥n del proyecto  
2. Acceso al proyecto  
3. Etapas del proyecto  
4. Descripci√≥n de los datos  
5. Resultados y conclusiones  
6. Tecnolog√≠as utilizadas  
7. Agradecimientos  
8. Desarrollador del proyecto  

---

## 1. Descripci√≥n del proyecto üìö  
Se implementaron modelos supervisados de Machine Learning para predecir cancelaciones de clientes en una empresa de telecomunicaciones. Se aplic√≥ preprocesamiento, an√°lisis de multicolinealidad y optimizaci√≥n de hiperpar√°metros.  
El modelo final fue seleccionado priorizando el **Recall**, buscando minimizar falsos negativos. Finalmente, se valid√≥ su uso con un pipeline productivo sobre datos sint√©ticos.

---



---

## 2. Etapas del proyecto üìù  
- Importaci√≥n de librer√≠as  
- Preprocesamiento: Encoding, normalizaci√≥n, correlaci√≥n  
- Modelado: √Årboles, regresi√≥n, SVM, KNN, XGBoost  
- Evaluaci√≥n: M√©tricas, sobreajuste/subajuste, importancia de variables  
- Simulaci√≥n en entorno productivo con pipeline  

---

## 3. Descripci√≥n de los datos üìä  
Se integraron dos datasets (`preprocessed_TelecomX_data.json`, `clientes_altovalor_abandonan.json`) con 7152 registros.  
Variables: 19 predictoras y 1 objetivo (Churn).  
Se aplic√≥ balanceo con **NearMiss v3** (reducci√≥n) y **SMOTENC** (simulaci√≥n).  
Transformaciones espec√≠ficas por tipo de modelo:

- √Årboles: One-hot encoding, sin escalado  
- Modelos lineales: One-hot (drop='first'), escalado con RobustScaler  
- KNN: One-hot (drop='if_binary'), escalado con RobustScaler  
- Objetivo (Churn): Label Encoding (`Yes`‚Üí1, `No`‚Üí0)  

---

## 4. Resultados y conclusiones ‚úçÔ∏è  

**Modelos evaluados:**  
- Random Forest  
- Logistic Regression  
- XGBoost  
- SVM  
- KNN (descartado por bajo Recall)

**M√©tricas destacadas (Recall ‚â• 0.85 con umbral modificado):**

| Modelo               | Recall | Precision | F1-score | AUC    |
|----------------------|--------|-----------|----------|--------|
| **Random Forest**    | 0.862  | 0.4914    | 0.6259   | 0.8326 |
| Logistic Regression  | 0.862  | 0.4539    | 0.5947   | 0.8137 |
| XGBoost              | 0.855  | 0.4695    | 0.6062   | 0.8188 |
| SVM                  | 0.862  | 0.4571    | 0.5974   | 0.8073 |

**Modelo campe√≥n:**  
**Random Forest**, por mayor capacidad de generalizaci√≥n y menor tasa de falsos positivos al alcanzar Recall ‚â• 0.85.

**Importancia de variables:**  
Visualizada en `RandomForest_importancias`, complementada con coeficientes de regresi√≥n log√≠stica para interpretar direcci√≥n e impacto.

**Pipeline productivo:**  
Recibe JSON con datos crudos y genera:

- `mode='production'`: Probabilidad y etiqueta de churn.  
- `mode='monitor'`: M√©tricas y log de ejecuci√≥n.

---

## 5. Tecnolog√≠as utilizadas üõ†Ô∏è  
- Python + Jupyter Notebook  
- Git & GitHub  

---

## 6. Agradecimientos ü§ù  
Gracias a **Oracle** y **Alura LATAM** por brindar los recursos de capacitaci√≥n para el desarrollo de este proyecto.

---

## 7. Desarrollador del proyecto üë∑  

| **Milan yb** | Data Scientist Junior |  
üì´ milanyb@gmail.com | üíª LinkedIn  
